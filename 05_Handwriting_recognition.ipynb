{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "def7c401",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6037cf59",
   "metadata": {},
   "source": [
    "We start with imports.\n",
    "\n",
    "Here we are importing TensorFlow and calling it tf for ease of use.\n",
    "\n",
    "And, Check version of TensorFlow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7e3c9cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "605ac7ff",
   "metadata": {},
   "source": [
    "# Callback"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57bdce79",
   "metadata": {},
   "source": [
    "Callback allows us to stop training once the training accuracy reaches a certain desired threshold. Thus, we can achieve what we want and avoid wastage of resources.\n",
    "\n",
    "We can callback to a code function, having checked the metrics.\n",
    "\n",
    "Callback is implemented as a separate class.\n",
    "\n",
    "Here we create a class - myCallback by extending tf.keras.callbacks.Callback\n",
    "\n",
    "In it, we'll implement the on_epoch_end function, which gets called by the callback whenever the epoch ends.\n",
    "\n",
    "It also sends a logs object which contains lots of great information about the current state of training.\n",
    "\n",
    "Here we are checking if the accuracy is greater than 0.9 and canceling the training itself.\n",
    "\n",
    "If accuracy is greater than our threshold, we are setting the stop_training of model to True.\n",
    "\n",
    "We instantiate the callback class with callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2fff24",
   "metadata": {},
   "outputs": [],
   "source": [
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epochs, logs={}):\n",
    "        if(logs.get('accuracy') is not None and logs.get('accuracy')>0.99):\n",
    "            print('\\nReached 99% accuracy so cancelling training!')\n",
    "            self.model.stop_training = True\n",
    "                \n",
    "callbacks = myCallback()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ba30159",
   "metadata": {},
   "source": [
    "# Providing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07aa5abc",
   "metadata": {},
   "source": [
    "The Fashion MNIST data is available directly in the tf.keras datasets API.\n",
    "\n",
    "We load it here.\n",
    "\n",
    "We declare an object - mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb4829d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fd34dc5",
   "metadata": {},
   "source": [
    "# Creating Training and Testing set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0141c9d5",
   "metadata": {},
   "source": [
    "We create the training and testing datasets for the items and their labels by calling load_data on the object - mnist.\n",
    "\n",
    "That's the training data, the training labels, the testing data, and the testing labels.\n",
    "\n",
    "It is important to use some of our data to train the neural network and similar data that the model hasn't yet seen to test how good it is at recognizing the images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2398c119",
   "metadata": {},
   "outputs": [],
   "source": [
    "(training_hw, training_labels), (test_hw, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6eb7a034",
   "metadata": {},
   "source": [
    "# Normalizing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d45d8e9",
   "metadata": {},
   "source": [
    "The values of pixels are in the number between 0 and 255.\n",
    "\n",
    "While training a neural network, for various reasons it's easier if we treat all values as between 0 and 1.\n",
    "\n",
    "It is called 'normalizing'.\n",
    "\n",
    "We do it here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0f91a5f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_hw = training_hw / 255.0\n",
    "test_hw = test_hw / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79b6579",
   "metadata": {},
   "source": [
    "# Define the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb4ab1b",
   "metadata": {},
   "source": [
    "Here we have 3 layers.\n",
    "\n",
    "Sequential defines a SEQUENCE of layers in the neural network.\n",
    "\n",
    "The first layer is a flatten layer with the input shaping 28 by 28. Flatten takes thae square(shape of images) and turns it into a 1 dimensional set(a simple linear array).\n",
    "\n",
    "The middle layer is sometimes also called a hidden layer. This has 1024 neurons in it.\n",
    "\n",
    "The last layer has 10 neurons in it because we have ten classes of clothing in the dataset.\n",
    "\n",
    "Dense adds a layer of neurons. Each layer of neurons need an activation function to tell them what to do.\n",
    "\n",
    "Relu effectively means \"If X>0 return X, else return 0\" -- so what it does it it only passes values 0 or greater to the next layer in the network.\n",
    "\n",
    "Softmax takes a set of values, and effectively picks the biggest one. It turns [0.1, 0.1, 0.05, 0.1, 9.5, 0.1, 0.05, 0.05, 0.05] into [0,0,0,0,1,0,0,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8b519d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape=(28,28)),\n",
    "                                    tf.keras.layers.Dense(1024, activation='relu'),\n",
    "                                    tf.keras.layers.Dense(10, activation='softmax')])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "621ed631",
   "metadata": {},
   "source": [
    "# Compile the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b09557f",
   "metadata": {},
   "source": [
    "While compiling our Neural Network we have to specify two functions, a loss and an optimizer.\n",
    "\n",
    "Computer makes a guess while trying to learn any relationship.\n",
    "\n",
    "The LOSS function measures the guessed answers against the known correct answers and measures how well or how badly it did.\n",
    "\n",
    "It then uses OPTIMIZER function to make another guess. Based on how the loss function went, it will try to minimize the loss.\n",
    "\n",
    "Here, we are using 'sparse_categorical_crossentropy' for the loss and 'Adam' for the optimizer.\n",
    "\n",
    "The Keras library provides a way to calculate and report on a suite of standard metrics when training deep learning models.\n",
    "\n",
    "This is particularly useful when we want to keep track of a performance measure that better captures the skill of our model during training. Here we will keep track of accuracy.\n",
    "\n",
    "We can do this by specifying the “metrics” argument.\n",
    "\n",
    "Regardless of whether our problem is a binary or multi-class classification problem, we can specify the ‘accuracy‘ metric to report on accuracy.\n",
    "\n",
    "Here we are using the built-in accuracy metric for multi-class classification problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7eb34831",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='Adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937b3db5",
   "metadata": {},
   "source": [
    "# Training the Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34306bd",
   "metadata": {},
   "source": [
    "We train the neural network using training data in model.fit. Here it learns the relationship between the image and the labels.\n",
    "\n",
    "It will go through the \"OPTIMIZER\" and \"LOSS\" loop for the number of epochs we specify.\n",
    "\n",
    "Here, we use the callbacks parameter in model.fit and pass it the instance of the class that we have created.\n",
    "\n",
    "The callback will hit at the end of the epoch, because the accuracy may vary up and down during the epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7fa0ce9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.1824 - accuracy: 0.9460\n",
      "Epoch 2/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0759 - accuracy: 0.9762\n",
      "Epoch 3/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0469 - accuracy: 0.9850\n",
      "Epoch 4/10\n",
      "1875/1875 [==============================] - 17s 9ms/step - loss: 0.0355 - accuracy: 0.9886\n",
      "Epoch 5/10\n",
      "1875/1875 [==============================] - 16s 9ms/step - loss: 0.0257 - accuracy: 0.9914\n",
      "\n",
      "Reached 99% accuracy so cancelling training!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x148fd47e8b0>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_hw, training_labels, epochs = 10, callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1aa0bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
